
@article{sinha_latent_2018,
	title = {Latent class analysis of {ARDS} subphenotypes: a secondary analysis of the statins for acutely injured lungs from sepsis ({SAILS}) study},
	volume = {44},
	issn = {1432-1238},
	shorttitle = {Latent class analysis of {ARDS} subphenotypes},
	url = {https://doi.org/10.1007/s00134-018-5378-3},
	doi = {10.1007/s00134-018-5378-3},
	abstract = {PurposeUsing latent class analysis (LCA), we have consistently identified two distinct subphenotypes in four randomized controlled trial cohorts of ARDS. One subphenotype has hyper-inflammatory characteristics and is associated with worse clinical outcomes. Further, within three negative clinical trials, we observed differential treatment response by subphenotype to randomly assigned interventions. The main purpose of this study was to identify ARDS subphenotypes in a contemporary NHLBI Network trial of infection-associated ARDS (SAILS) using LCA and to test for differential treatment response to rosuvastatin therapy in the subphenotypes.MethodsLCA models were constructed using a combination of biomarker and clinical data at baseline in the SAILS study (n = 745). LCA modeling was then repeated using an expanded set of clinical class-defining variables. Subphenotypes were tested for differential treatment response to rosuvastatin.ResultsThe two-class LCA model best fit the population. Forty percent of the patients were classified as the “hyper-inflammatory” subphenotype. Including additional clinical variables in the LCA models did not identify new classes. Mortality at day 60 and day 90 was higher in the hyper-inflammatory subphenotype. No differences in outcome were observed between hyper-inflammatory patients randomized to rosuvastatin therapy versus placebo.ConclusionsLCA using a two-subphenotype model best described the SAILS population. The subphenotypes have features consistent with those previously reported in four other cohorts. Addition of new class-defining variables in the LCA model did not yield additional subphenotypes. No treatment effect was observed with rosuvastatin. These findings further validate the presence of two subphenotypes and demonstrate their utility for patient stratification in ARDS.},
	language = {en},
	number = {11},
	urldate = {2019-06-10},
	journal = {Intensive Care Medicine},
	author = {Sinha, Pratik and Delucchi, Kevin L. and Thompson, B. Taylor and McAuley, Daniel F. and Matthay, Michael A. and Calfee, Carolyn S. and {for the NHLBI ARDS Network}},
	month = nov,
	year = {2018},
	keywords = {ARDS, Latent class analysis, Statins, Subphenotypes},
	pages = {1859--1869},
	file = {Springer Full Text PDF:/Users/Berto/Zotero/storage/VTS8N8J7/Sinha et al. - 2018 - Latent class analysis of ARDS subphenotypes a sec.pdf:application/pdf}
}

@article{calfee_acute_2018,
	title = {Acute respiratory distress syndrome subphenotypes and differential response to simvastatin: secondary analysis of a randomised controlled trial},
	volume = {6},
	abstract = {Background Precision medicine approaches that target patients on the basis of disease subtype have transformed
treatment approaches to cancer, asthma, and other heterogeneous syndromes. Two distinct subphenotypes of acute
respiratory distress syndrome (ARDS) have been identified in three US-based clinical trials, and these subphenotypes
respond differently to positive end-expiratory pressure and fluid management. We aimed to investigate whether these
subphenotypes exist in non-US patient populations and respond differently to pharmacotherapies.
Methods HARP-2 was a multicentre, randomised controlled trial of simvastatin (80 mg) versus placebo done in general
intensive care units (ICUs) at 40 hospitals in the UK and Ireland within 48 h of onset of ARDS. The primary outcome
was ventilator-free days, and secondary outcomes included non-pulmonary organ failure-free days and mortality. In a
secondary analysis of HARP-2, we applied latent class analysis to baseline data without consideration of outcomes to
identify subphenotypes, and we compared clinical outcomes across subphenotypes and treatment groups.
Findings 540 patients were recruited to HARP-2. One patient withdrew consent for the use of their data, so data from
539 patients were analysed. In our secondary analysis, a two-class (two subphenotype) model was an improvement
over a one-class model (p{\textless}0·0001), with 353 (65\%) patients in the hypoinflammatory subphenotype group and
186 (35\%) in the hyperinflammatory subphenotype group. Additional classes did not improve model fit. Clinical and
biological characteristics of the two subphenotypes were similar to previous studies. Patients with the
hyperinflammatory subphenotype had fewer ventilator-free days (median 2 days [IQR 0–17] vs 18 [IQR 0–23];
p{\textless}0·0001), fewer non-pulmonary organ failure-free days (15 [0–25] vs 27 [21–28]; p{\textless}0·0001), and higher 28-day
mortality (73 [39\%] vs 59 [17\%]; p{\textless}0·0001) than did those with the hypoinflammatory subphenotype. Although
HARP-2 found no difference in 28-day survival between placebo and simvastatin, significantly different survival was
identified across patients stratified by treatment and subphenotype (p{\textless}0·0001). Specifically, within the
hyperinflammatory subphenotype, patients treated with simvastatin had significantly higher 28-day survival than did
those given placebo (p=0·008). A similar pattern was observed for 90-day survival.
Interpretation Two subphenotypes of ARDS were identified in the HARP-2 cohort, with distinct clinical and biological
features and disparate clinical outcomes. The hyperinflammatory subphenotype had improved survival with
simvastatin compared with placebo. These findings support further pursuit of predictive enrichment strategies in
critical care clinical trials.
Funding UK Efficacy and Mechanism Evaluation Programme and National Institutes of Health.},
	language = {English},
	number = {9},
	urldate = {2019-06-10},
	journal = {The Lancet Respiratory Medicine},
	author = {Calfee, Carolyn S},
	month = sep,
	year = {2018},
	pages = {691--698}
}

@article{beretta_nearest_2016,
	title = {Nearest neighbor imputation algorithms: a critical evaluation},
	volume = {16},
	issn = {1472-6947},
	shorttitle = {Nearest neighbor imputation algorithms},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959387/},
	doi = {10.1186/s12911-016-0318-z},
	abstract = {Background
Nearest neighbor (NN) imputation algorithms are efficient methods to fill in missing data where each missing value on some records is replaced by a value obtained from related cases in the whole set of records. Besides the capability to substitute the missing data with plausible values that are as close as possible to the true value, imputation algorithms should preserve the original data structure and avoid to distort the distribution of the imputed variable. Despite the efficiency of NN algorithms little is known about the effect of these methods on data structure.

Methods
Simulation on synthetic datasets with different patterns and degrees of missingness were conducted to evaluate the performance of NN with one single neighbor (1NN) and with k neighbors without (kNN) or with weighting (wkNN) in the context of different learning frameworks: plain set, reduced set after ReliefF filtering, bagging, random choice of attributes, bagging combined with random choice of attributes (Random-Forest-like method).

Results
Whatever the framework, kNN usually outperformed 1NN in terms of precision of imputation and reduced errors in inferential statistics, 1NN was however the only method capable of preserving the data structure and data were distorted even when small values of k neighbors were considered; distortion was more severe for resampling schemas.

Conclusions
The use of three neighbors in conjunction with ReliefF seems to provide the best trade-off between imputation error and preservation of the data structure. The very same conclusions can be drawn when imputation experiments were conducted on the single proton emission computed tomography (SPECTF) heart dataset after introduction of missing data completely at random.},
	number = {Suppl 3},
	urldate = {2019-06-11},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Beretta, Lorenzo and Santaniello, Alessandro},
	month = jul,
	year = {2016},
	pmid = {27454392},
	pmcid = {PMC4959387},
	file = {PubMed Central Full Text PDF:/Users/Berto/Zotero/storage/Y6EK8RYX/Beretta and Santaniello - 2016 - Nearest neighbor imputation algorithms a critical.pdf:application/pdf}
}

@inproceedings{caruana_empirical_2006,
	title = {An empirical comparison of supervised learning algorithms},
	isbn = {978-1-59593-383-6},
	url = {http://portal.acm.org/citation.cfm?doid=1143844.1143865},
	doi = {10.1145/1143844.1143865},
	abstract = {A number of supervised learning methods have been introduced in the last decade. Unfortunately, the last comprehensive empirical evaluation of supervised learning was the Statlog Project in the early 90’s. We present a large-scale empirical comparison between ten supervised learning methods: SVMs, neural nets, logistic regression, naive bayes, memory-based learning, random forests, decision trees, bagged trees, boosted trees, and boosted stumps. We also examine the eﬀect that calibrating the models via Platt Scaling and Isotonic Regression has on their performance. An important aspect of our study is the use of a variety of performance criteria to evaluate the learning methods.},
	language = {en},
	urldate = {2019-07-02},
	publisher = {ACM Press},
	author = {Caruana, Rich and Niculescu-Mizil, Alexandru},
	year = {2006},
	pages = {161--168},
	file = {Caruana and Niculescu-Mizil - 2006 - An empirical comparison of supervised learning alg.pdf:/Users/Berto/Zotero/storage/QUHQTQKK/Caruana and Niculescu-Mizil - 2006 - An empirical comparison of supervised learning alg.pdf:application/pdf}
}

@article{calfee_subphenotypes_2014,
	title = {Subphenotypes in acute respiratory distress syndrome: latent class analysis of data from two randomised controlled trials},
	volume = {2},
	issn = {22132600},
	shorttitle = {Subphenotypes in acute respiratory distress syndrome},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2213260014700979},
	doi = {10.1016/S2213-2600(14)70097-9},
	language = {en},
	number = {8},
	urldate = {2019-07-02},
	journal = {The Lancet Respiratory Medicine},
	author = {Calfee, Carolyn S and Delucchi, Kevin and Parsons, Polly E and Thompson, B Taylor and Ware, Lorraine B and Matthay, Michael A},
	month = aug,
	year = {2014},
	pages = {611--620},
	file = {Accepted Version:/Users/Berto/Zotero/storage/CA3Y52SW/Calfee et al. - 2014 - Subphenotypes in acute respiratory distress syndro.pdf:application/pdf}
}

@article{duchi_efcient_nodate,
	title = {Efﬁcient {Learning} using {Forward}-{Backward} {Splitting}},
	abstract = {We describe, analyze, and experiment with a new framework for empirical loss minimization with regularization. Our algorithmic framework alternates between two phases. On each iteration we ﬁrst perform an unconstrained gradient descent step. We then cast and solve an instantaneous optimization problem that trades off minimization of a regularization term while keeping close proximity to the result of the ﬁrst phase. This yields a simple yet effective algorithm for both batch penalized risk minimization and online learning. Furthermore, the two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity, such as ℓ1. We derive concrete and very simple algorithms for minimization of loss functions with ℓ1, ℓ2, ℓ22, and ℓ∞ regularization. We also show how to construct efﬁcient algorithms for mixed-norm ℓ1/ℓq regularization. We further extend the algorithms and give efﬁcient implementations for very high-dimensional data with sparsity. We demonstrate the potential of the proposed framework in experiments with synthetic and natural datasets.},
	language = {en},
	author = {Duchi, John and Singer, Yoram},
	pages = {15},
	file = {Duchi and Singer - Efﬁcient Learning using Forward-Backward Splitting.pdf:/Users/Berto/Zotero/storage/EXV2K2QG/Duchi and Singer - Efﬁcient Learning using Forward-Backward Splitting.pdf:application/pdf}
}

@misc{noauthor_doi:10.1016/j.jspi.2004.10.024_nodate,
	title = {doi:10.1016/j.jspi.2004.10.024 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {doi},
	url = {https://reader.elsevier.com/reader/sd/pii/S0378375804004380?token=DF1DE287C4B3069147F95C82BF69B11E96862D0CAEA999A38007B45D86067FC30F5526ACC1898C005D402B9153E6F340},
	language = {en},
	urldate = {2019-07-03},
	doi = {10.1016/j.jspi.2004.10.024},
	file = {Full Text:/Users/Berto/Zotero/storage/HZZ9S9BV/doi10.1016j.jspi.2004.10.024  Elsevier Enhanced.pdf:application/pdf;Snapshot:/Users/Berto/Zotero/storage/GN34ZWL4/S0378375804004380.html:text/html}
}

@article{noauthor_handling_2014,
	title = {Handling missing values in kernel methods with application to microbiology data},
	volume = {141},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231214003907},
	doi = {10.1016/j.neucom.2014.01.047},
	abstract = {We discuss several approaches that make possible for kernel methods to deal with missing values for binary variables. The first two are extended kerne…},
	language = {en},
	urldate = {2019-08-10},
	journal = {Neurocomputing},
	month = oct,
	year = {2014},
	keywords = {ensemble, imputation, pooling},
	pages = {110--116}
}

@inproceedings{alasalmi_classification_2015,
	title = {Classification {Uncertainty} of {Multiple} {Imputed} {Data}},
	doi = {10.1109/SSCI.2015.32},
	abstract = {Every classification model contains uncertainty. This uncertainty can be distributed evenly or into certain areas of feature space. In regular classification tasks, the uncertainty can be estimated from posterior probabilities. On the other hand, if the data set contains missing values, not all classifiers can be used directly. Imputing missing values solves this problem but it suppresses variation in the data leading to underestimation of uncertainty and can also bias the results. Multiple imputation, where several copies of the data set are created, solves these problems but the classical approach for uncertainty estimation does not generalize to this case. Thus in this paper we propose a novel algorithm to estimate classification uncertainty with multiple imputed data. We show that the algorithm performs as well as the benchmark algorithm with a classifier that supports classification with missing values. It also supports the use of any classifier, even if it does not support classification with missing values, as long as it supports the estimation of posterior probabilities.},
	booktitle = {2015 {IEEE} {Symposium} {Series} on {Computational} {Intelligence}},
	author = {Alasalmi, T. and Koskimäki, H. and Suutala, J. and Röning, J.},
	month = dec,
	year = {2015},
	keywords = {Analytical models, classification, classification model, classification uncertainty estimation, Correlation, Data handling, Data models, ensemble, imputed data classification, Machine learning algorithms, multiple imputation, pattern classification, posterior probability estimation, probability, Support vector machines, Uncertainty},
	pages = {151--158},
	file = {IEEE Xplore Abstract Record:/Users/Berto/Zotero/storage/YC8LPLUB/7376605.html:text/html;IEEE Xplore Full Text PDF:/Users/Berto/Zotero/storage/655JS4SQ/Alasalmi et al. - 2015 - Classification Uncertainty of Multiple Imputed Dat.pdf:application/pdf}
}

@misc{van_buuren_flexible_nodate,
	title = {Flexible {Imputation} of {Missing} {Data}, {Second} {Edition}},
	url = {https://www.taylorfrancis.com/books/e/9780429492259},
	abstract = {Missing data pose challenges to real-life data analysis. Simple ad-hoc fixes, like deletion or mean imputation, only work under highly restrictive conditions,},
	language = {en},
	urldate = {2019-08-10},
	journal = {Taylor \& Francis},
	author = {van Buuren, Stef},
	keywords = {missing data, multiple imputation},
	file = {Snapshot:/Users/Berto/Zotero/storage/X2NADXFQ/9780429492259.html:text/html}
}

@book{van_buuren_flexible_2012,
	address = {London},
	edition = {Second Edition},
	title = {Flexible {Imputation} of {Missing} {Data}},
	abstract = {Missing data form a problem in every scientific discipline, yet the techniques required to handle them are complicated and often lacking. One of the great ideas in statistical science—multiple imputation—fills gaps in the data with plausible values, the uncertainty of which is coded in the data itself. It also solves other problems, many of which are missing data problems in disguise.},
	publisher = {Chapman \& Hall},
	author = {van Buuren, Stef},
	year = {2012}
}

@article{van_buuren_mice:_2000,
	title = {{MICE}: {Multivariate} imputation by chained equations ({S} software for missing-data imputation},
	url = {http://web.inter.nl.net/users/S.van.Buuren/mi/},
	author = {van Buuren, Stef and Oudshoom, C. G. M.},
	year = {2000}
}